{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7faa1f8b",
   "metadata": {},
   "source": [
    "# 1.初步处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acfb8163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X16  X17  X18  X19  X20  \\\n",
       " 0     1   6   4  12   5   5   3   4   1   67  ...    0    0    1    0    0   \n",
       " 1     2  48   2  60   1   3   2   2   1   22  ...    0    0    1    0    0   \n",
       " 2     4  12   4  21   1   4   3   3   1   49  ...    0    0    1    0    0   \n",
       " 3     1  42   2  79   1   4   3   4   2   45  ...    0    0    0    0    0   \n",
       " 4     1  24   3  49   1   3   3   4   4   53  ...    1    0    1    0    0   \n",
       " ..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       " 995   4  12   2  17   1   4   2   4   1   31  ...    0    0    1    0    0   \n",
       " 996   1  30   2  39   1   3   1   4   2   40  ...    0    1    1    0    0   \n",
       " 997   4  12   2   8   1   5   3   4   3   38  ...    0    0    1    0    0   \n",
       " 998   1  45   2  18   1   3   3   4   4   23  ...    0    0    1    0    0   \n",
       " 999   2  45   4  46   2   1   3   4   3   27  ...    0    1    1    0    0   \n",
       " \n",
       "      X21  X22  X23  X24  Y(1=default, 0=non-default)  \n",
       " 0      1    0    0    1                            0  \n",
       " 1      1    0    0    1                            1  \n",
       " 2      1    0    1    0                            0  \n",
       " 3      0    0    0    1                            0  \n",
       " 4      0    0    0    1                            1  \n",
       " ..   ...  ...  ...  ...                          ...  \n",
       " 995    1    0    1    0                            0  \n",
       " 996    1    0    0    0                            0  \n",
       " 997    1    0    0    1                            0  \n",
       " 998    0    0    0    1                            1  \n",
       " 999    1    0    0    1                            0  \n",
       " \n",
       " [1000 rows x 25 columns],\n",
       "      X1     X2      X3  X4  X5  X6     X7  X8  X9  X10  X11  X12  X13   X14  \\\n",
       " 0     1  22.08  11.460   2   4   4  1.585   0   0    0    1    2  100  1213   \n",
       " 1     0  22.67   7.000   2   8   4  0.165   0   0    0    0    2  160     1   \n",
       " 2     0  29.58   1.750   1   4   4  1.250   0   0    0    1    2  280     1   \n",
       " 3     0  21.67  11.500   1   5   3  0.000   1   1   11    1    2    0     1   \n",
       " 4     1  20.17   8.170   2   6   4  1.960   1   1   14    0    2   60   159   \n",
       " ..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ...  ...  ...  ...   ...   \n",
       " 685   1  31.57  10.500   2  14   4  6.500   1   0    0    0    2    0     1   \n",
       " 686   1  20.67   0.415   2   8   4  0.125   0   0    0    0    2    0    45   \n",
       " 687   0  18.83   9.540   2   6   4  0.085   1   0    0    0    2  100     1   \n",
       " 688   0  27.42  14.500   2  14   8  3.085   1   1    1    0    2  120    12   \n",
       " 689   1  41.00   0.040   2  10   4  0.040   0   1    1    0    1  560     1   \n",
       " \n",
       "      Y(1=default, 0=non-default)  \n",
       " 0                              1  \n",
       " 1                              1  \n",
       " 2                              1  \n",
       " 3                              0  \n",
       " 4                              0  \n",
       " ..                           ...  \n",
       " 685                            0  \n",
       " 686                            1  \n",
       " 687                            0  \n",
       " 688                            0  \n",
       " 689                            0  \n",
       " \n",
       " [690 rows x 15 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import pandas as pd\n",
    "\n",
    "german_credit_data = pd.read_csv('add1.csv')\n",
    "australian_credit_data = pd.read_csv('add2.csv')\n",
    "\n",
    "german_credit_data, australian_credit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e445b",
   "metadata": {},
   "source": [
    "# 2.现有模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bcde5d",
   "metadata": {},
   "source": [
    "## 2.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4a9435f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# 评估模型并返回所需指标的函数\n",
    "def evaluate_model(data, model):\n",
    "    X = data.drop(columns=['Y(1=default, 0=non-default)']).values\n",
    "    y = data['Y(1=default, 0=non-default)'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    type1_error = conf_matrix[0, 1] / conf_matrix.sum()\n",
    "    type2_error = conf_matrix[1, 0] / conf_matrix.sum()\n",
    "    return accuracy, auc, type1_error, type2_error\n",
    "\n",
    "# 初始化分类器\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 德国数据集评估\n",
    "german_results = evaluate_model(german_credit_data, dt_classifier)\n",
    "\n",
    "# 澳大利亚数据集评估\n",
    "australian_results = evaluate_model(australian_credit_data, dt_classifier)\n",
    "\n",
    "# 创建结果表格\n",
    "german_table = pd.DataFrame({\n",
    "    \"模型\": [\"DT\"],\n",
    "    \"Accuracy\": [german_results[0]],\n",
    "    \"AUC\": [german_results[1]],\n",
    "    \"Type1-error\": [german_results[2]],\n",
    "    \"Type2-error\": [german_results[3]]\n",
    "})\n",
    "\n",
    "australian_table = pd.DataFrame({\n",
    "    \"模型\": [\"DT\"],\n",
    "    \"Accuracy\": [australian_results[0]],\n",
    "    \"AUC\": [australian_results[1]],\n",
    "    \"Type1-error\": [australian_results[2]],\n",
    "    \"Type2-error\": [australian_results[3]]\n",
    "})\n",
    "\n",
    "# 保存到CSV\n",
    "german_table_path = '德国.csv'\n",
    "australian_table_path = '澳大利亚.csv'\n",
    "german_table.to_csv(german_table_path, index=False, encoding='utf-8-sig')\n",
    "australian_table.to_csv(australian_table_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1bb8d7",
   "metadata": {},
   "source": [
    "## 2.2 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "aa061647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 初始化\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 德国\n",
    "german_knn_results = evaluate_model(german_credit_data, knn_classifier)\n",
    "\n",
    "# 澳大利亚\n",
    "australian_knn_results = evaluate_model(australian_credit_data, knn_classifier)\n",
    "\n",
    "# 更新结果表格\n",
    "german_table = pd.concat([german_table, pd.DataFrame({\n",
    "    \"模型\": [\"KNN\"],\n",
    "    \"Accuracy\": [german_knn_results[0]],\n",
    "    \"AUC\": [german_knn_results[1]],\n",
    "    \"Type1-error\": [german_knn_results[2]],\n",
    "    \"Type2-error\": [german_knn_results[3]]\n",
    "})], ignore_index=True)\n",
    "\n",
    "australian_table = pd.concat([australian_table, pd.DataFrame({\n",
    "    \"模型\": [\"KNN\"],\n",
    "    \"Accuracy\": [australian_knn_results[0]],\n",
    "    \"AUC\": [australian_knn_results[1]],\n",
    "    \"Type1-error\": [australian_knn_results[2]],\n",
    "    \"Type2-error\": [australian_knn_results[3]]\n",
    "})], ignore_index=True)\n",
    "\n",
    "# 保存\n",
    "german_table.to_csv(german_table_path, index=False, encoding='utf-8-sig')\n",
    "australian_table.to_csv(australian_table_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd59a1",
   "metadata": {},
   "source": [
    "## 2.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "73c56dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 初始化\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 德国\n",
    "german_rf_results = evaluate_model(german_credit_data, rf_classifier)\n",
    "\n",
    "# 澳大利亚\n",
    "australian_rf_results = evaluate_model(australian_credit_data, rf_classifier)\n",
    "\n",
    "# 更新\n",
    "german_table = pd.concat([german_table, pd.DataFrame({\n",
    "    \"模型\": [\"RF\"],\n",
    "    \"Accuracy\": [german_rf_results[0]],\n",
    "    \"AUC\": [german_rf_results[1]],\n",
    "    \"Type1-error\": [german_rf_results[2]],\n",
    "    \"Type2-error\": [german_rf_results[3]]\n",
    "})], ignore_index=True)\n",
    "\n",
    "australian_table = pd.concat([australian_table, pd.DataFrame({\n",
    "    \"模型\": [\"RF\"],\n",
    "    \"Accuracy\": [australian_rf_results[0]],\n",
    "    \"AUC\": [australian_rf_results[1]],\n",
    "    \"Type1-error\": [australian_rf_results[2]],\n",
    "    \"Type2-error\": [australian_rf_results[3]]\n",
    "})], ignore_index=True)\n",
    "\n",
    "# 保存\n",
    "german_table.to_csv(german_table_path, index=False, encoding='utf-8-sig')\n",
    "australian_table.to_csv(australian_table_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d016a9c",
   "metadata": {},
   "source": [
    "## 2.4 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e714f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# 初始化\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# 德国\n",
    "german_svm_results = evaluate_model(german_credit_data, svm_classifier)\n",
    "\n",
    "# 澳大利亚\n",
    "australian_svm_results = evaluate_model(australian_credit_data, svm_classifier)\n",
    "\n",
    "# 更新\n",
    "german_table = pd.concat([german_table, pd.DataFrame({\n",
    "    \"模型\": [\"SVM\"],\n",
    "    \"Accuracy\": [german_svm_results[0]],\n",
    "    \"AUC\": [german_svm_results[1]],\n",
    "    \"Type1-error\": [german_svm_results[2]],\n",
    "    \"Type2-error\": [german_svm_results[3]]\n",
    "})], ignore_index=True)\n",
    "\n",
    "australian_table = pd.concat([australian_table, pd.DataFrame({\n",
    "    \"模型\": [\"SVM\"],\n",
    "    \"Accuracy\": [australian_svm_results[0]],\n",
    "    \"AUC\": [australian_svm_results[1]],\n",
    "    \"Type1-error\": [australian_svm_results[2]],\n",
    "    \"Type2-error\": [australian_svm_results[3]]\n",
    "})], ignore_index=True)\n",
    "\n",
    "# 保存\n",
    "german_table.to_csv(german_table_path, index=False, encoding='utf-8-sig')\n",
    "australian_table.to_csv(australian_table_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922d764",
   "metadata": {},
   "source": [
    "# 3.我们的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478edf33",
   "metadata": {},
   "source": [
    "## 3.1 同第一问，对附件2进行IV值计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af7c455d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IV Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>0.000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>0.124104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>0.231719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>0.193455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>0.659985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>0.302602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X7</th>\n",
       "      <td>0.640154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X8</th>\n",
       "      <td>2.818864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X9</th>\n",
       "      <td>0.910995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X10</th>\n",
       "      <td>2.121855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X11</th>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X12</th>\n",
       "      <td>0.058358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>0.164355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14</th>\n",
       "      <td>0.691102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IV Value\n",
       "X1   0.000781\n",
       "X2   0.124104\n",
       "X3   0.231719\n",
       "X4   0.193455\n",
       "X5   0.659985\n",
       "X6   0.302602\n",
       "X7   0.640154\n",
       "X8   2.818864\n",
       "X9   0.910995\n",
       "X10  2.121855\n",
       "X11  0.004049\n",
       "X12  0.058358\n",
       "X13  0.164355\n",
       "X14  0.691102"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('add2.csv')\n",
    "\n",
    "# 定义划分区间的函数\n",
    "def binning_feature(data, feature):\n",
    "    bins = np.quantile(data[feature].dropna(), [0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    binned_feature = pd.cut(data[feature], bins, labels=False, duplicates='drop')\n",
    "    return binned_feature\n",
    "\n",
    "# 定义计算IV的函数\n",
    "def calculate_iv(data, feature, target):\n",
    "    total_bad = data[target].sum()\n",
    "    total_good = data[target].count() - total_bad\n",
    "    grouped = data.groupby(feature)[target].agg(['sum', 'count'])\n",
    "    grouped.columns = ['bad', 'total']\n",
    "    grouped['good'] = grouped['total'] - grouped['bad']\n",
    "\n",
    "    # 避免分母为零的情况\n",
    "    grouped['Bi'] = np.where(grouped['bad'] == 0, 0.00001, grouped['bad'] / total_bad)\n",
    "    grouped['Gi'] = np.where(grouped['good'] == 0, 0.00001, grouped['good'] / total_good)\n",
    "\n",
    "    grouped['WOE'] = np.log(grouped['Bi'] / grouped['Gi'])\n",
    "    grouped['IV'] = (grouped['Bi'] - grouped['Gi']) * grouped['WOE']\n",
    "\n",
    "    feature_iv = grouped['IV'].sum()\n",
    "    return feature_iv\n",
    "\n",
    "# 为特定的连续特征划分区间\n",
    "for feature in ['X2', 'X3', 'X7', 'X13', 'X14']:\n",
    "    data[feature] = binning_feature(data, feature)\n",
    "\n",
    "# 计算所有特征的IV值\n",
    "iv_results = {}\n",
    "for col in data.columns:\n",
    "    if col != 'Y(1=default, 0=non-default)': \n",
    "        iv_results[col] = calculate_iv(data, col, 'Y(1=default, 0=non-default)')\n",
    "\n",
    "iv_df = pd.DataFrame.from_dict(iv_results, orient='index', columns=['IV Value'])\n",
    "iv_df.to_csv('IV值2.csv', index=True)\n",
    "\n",
    "iv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02e0cf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IV Value</th>\n",
       "      <th>价值分类</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>0.124104</td>\n",
       "      <td>中价值特征</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>0.231719</td>\n",
       "      <td>中价值特征</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>0.193455</td>\n",
       "      <td>中价值特征</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>0.302602</td>\n",
       "      <td>强价值特征</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>0.164355</td>\n",
       "      <td>中价值特征</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IV Value   价值分类\n",
       "X2   0.124104  中价值特征\n",
       "X3   0.231719  中价值特征\n",
       "X4   0.193455  中价值特征\n",
       "X6   0.302602  强价值特征\n",
       "X13  0.164355  中价值特征"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize_iv(value):\n",
    "    if value < 0.02:\n",
    "        return '无用特征'\n",
    "    elif 0.02 <= value < 0.1:\n",
    "        return '弱价值特征'\n",
    "    elif 0.1 <= value < 0.3:\n",
    "        return '中价值特征'\n",
    "    elif 0.3 <= value < 0.5:\n",
    "        return '强价值特征'\n",
    "    else:\n",
    "        return '价值过高，不真实'\n",
    "\n",
    "# 存储标签\n",
    "iv_df['价值分类'] = iv_df['IV Value'].apply(categorize_iv)\n",
    "\n",
    "# 筛选\n",
    "filtered_iv_df = iv_df[iv_df['价值分类'].isin(['中价值特征', '强价值特征'])]\n",
    "\n",
    "filtered_data_path = '筛选2.csv'\n",
    "filtered_iv_df.to_csv(filtered_data_path, index=True)\n",
    "\n",
    "filtered_iv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "588db40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X6</th>\n",
       "      <th>X13</th>\n",
       "      <th>Y(1=default, 0=non-default)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X2      X3  X4  X6  X13  Y(1=default, 0=non-default)\n",
       "0    22.08  11.460   2   4  100                            1\n",
       "1    22.67   7.000   2   4  160                            1\n",
       "2    29.58   1.750   1   4  280                            1\n",
       "3    21.67  11.500   1   3    0                            0\n",
       "4    20.17   8.170   2   4   60                            0\n",
       "..     ...     ...  ..  ..  ...                          ...\n",
       "685  31.57  10.500   2   4    0                            0\n",
       "686  20.67   0.415   2   4    0                            1\n",
       "687  18.83   9.540   2   4  100                            0\n",
       "688  27.42  14.500   2   8  120                            0\n",
       "689  41.00   0.040   2   4  560                            0\n",
       "\n",
       "[690 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('add2.csv')\n",
    "\n",
    "#从源文件中提取筛选后的数据\n",
    "selected_features = [\n",
    "    'X2', 'X3', 'X4', 'X6', 'X13', 'Y(1=default, 0=non-default)'\n",
    "]\n",
    "filtered_data = data[selected_features]\n",
    "\n",
    "output_path = '筛选add2.csv'\n",
    "filtered_data.to_csv(output_path, index=False)\n",
    "\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a305d345",
   "metadata": {},
   "source": [
    "## 3.2 模型构建与运行（在阿里云上运行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46758a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "german_data_path = '筛选add1.csv' \n",
    "australian_data_path = '筛选add2.csv' \n",
    "german_data = pd.read_csv(german_data_path)\n",
    "australian_data = pd.read_csv(australian_data_path)\n",
    "\n",
    "# 数据预处理函数\n",
    "def preprocess_data(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(data.drop(columns=['Y(1=default, 0=non-default)']))\n",
    "    y = data['Y(1=default, 0=non-default)'].values\n",
    "    return X, y\n",
    "\n",
    "# 构建模型函数\n",
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=input_dim, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 评估模型函数\n",
    "def evaluate_model(X, y, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    type1_error = conf_matrix[0, 1] / conf_matrix.sum()\n",
    "    type2_error = conf_matrix[1, 0] / conf_matrix.sum()\n",
    "    return accuracy, auc, type1_error, type2_error\n",
    "\n",
    "X_german, y_german = preprocess_data(german_data)\n",
    "X_australian, y_australian = preprocess_data(australian_data)\n",
    "\n",
    "german_model = build_model(X_german.shape[1])\n",
    "australian_model = build_model(X_australian.shape[1])\n",
    "\n",
    "german_results = evaluate_model(X_german, y_german, german_model)\n",
    "australian_results = evaluate_model(X_australian, y_australian, australian_model)\n",
    "\n",
    "# 读取结果表格\n",
    "german_table = pd.read_csv('德国.csv')  \n",
    "australian_table = pd.read_csv('澳大利亚.csv') \n",
    "\n",
    "# 保存到CSV\n",
    "german_table = german_table.append({'模型': '我们的模型', \n",
    "                                    'Accuracy': german_results[0],\n",
    "                                    'AUC': german_results[1],\n",
    "                                    'Type1-error': german_results[2],\n",
    "                                    'Type2-error': german_results[3]}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "australian_table = australian_table.append({'模型': '我们的模型', \n",
    "                                            'Accuracy': australian_results[0],\n",
    "                                            'AUC': australian_results[1],\n",
    "                                            'Type1-error': australian_results[2],\n",
    "                                            'Type2-error': australian_results[3]}, \n",
    "                                           ignore_index=True)\n",
    "\n",
    "german_table.to_csv(german_table_path, index=False, encoding='utf-8-sig')\n",
    "australian_table.to_csv(australian_table_path, index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
